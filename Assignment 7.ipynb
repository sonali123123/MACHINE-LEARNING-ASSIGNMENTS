{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b214e21f",
   "metadata": {},
   "source": [
    "# Machine Learning Assignment 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0674f3",
   "metadata": {},
   "source": [
    "### 1. What is the definition of a target function ? In the sense of a real-life example, express the target function. How is a target function's fitness assessed ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f6203c",
   "metadata": {},
   "source": [
    "Ans(1) A target function, in machine learning, is a method for solving a problem that an AI algorithm parses its training data to find. Once an algorithm finds its target function, that function can be used to predict results (predictive analysis). The function can then be used to find output data related to inputs for real problems where, unlike training sets, outputs are not included.\n",
    "\n",
    "\n",
    "The target function is essentially the formula that an algorithm feeds data to in order to calculate predictions. As in algebra, it is common when training AI to find the variable from the solution, working in reverse. The function as defined by f is applied to the input (I) to produce the output (I), Therefore O= f(I).\n",
    "\n",
    "\n",
    "Analyzing the massive amounts of data related to its given problem, an AI derives understanding of previously unspecified rules by detecting consistencies in the data. The observations of inherent rules about how the studied subject operates inform the AI on how to process future data that does not include an output by applying this previously unknown function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1e3442",
   "metadata": {},
   "source": [
    "### 2. What are predictive models, and how do they work? What are descriptive types, and how do you use them? Examples of both types of models should be provided. Distinguish between these two forms of models ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f62eff9",
   "metadata": {},
   "source": [
    "Ans: In short, predictive modeling is a statistical technique using machine learning and data mining to predict and forecast likely future outcomes with the aid of historical and existing data.\n",
    "\n",
    "\n",
    "It works by analyzing current and historical data and projecting what it learns on a model generated to forecast likely outcomes.\n",
    "\n",
    "\n",
    "The three main types of descriptive studies are Case studies, Naturalistic observation, and Surveys.\n",
    "\n",
    "\n",
    "Some examples of descriptive research are: A specialty food group launching a new range of barbecue rubs would like to understand what flavors of rubs are favored by different people.\n",
    "\n",
    "\n",
    "Case Studies are a type of observational research that involve a thorough descriptive analysis of a single individual, group, or event. There is no single way to conduct a case study so researchers use a range of methods from unstructured interviewing to direct observation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4639e03",
   "metadata": {},
   "source": [
    "### 3. Describe the method of assessing a classification model's efficiency in detail. Describe the various measurement parameters ?\n",
    "Ans: Logarithmic loss (or log loss) measures the performance of a classification model where the prediction is a probability value between 0 and 1.\n",
    "\n",
    "\n",
    "Log loss increases as the predicted probability diverge from the actual label. Log loss is a widely used metric for Kaggle competitions. Input on the most important basics for the measurement of the physical parameters: Temperature, flow velocity, humidity, pressure, CO2 and infrared. Tips on correct measurement and for avoiding measurement errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8d918a",
   "metadata": {},
   "source": [
    "Model Evaluation Metrics are given below\n",
    "\n",
    "\n",
    "![title](https://miro.medium.com/max/1180/1*fXEeMWoPzuYxMxfCeDz9ag.jpeg)\n",
    "\n",
    "\n",
    "![title](https://miro.medium.com/max/1400/1*UVP_xb4F6J-M-xH3haz5Jw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52635322",
   "metadata": {},
   "source": [
    "#### 4. Describe :\n",
    "In the sense of machine learning models, what is underfitting? What is the most common reason for underfitting ?\n",
    "\n",
    "\n",
    "What does it mean to overfit? When is it going to happen?\n",
    "\n",
    "\n",
    "In the sense of model fitting, explain the bias-variance trade-off."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4792f5",
   "metadata": {},
   "source": [
    "Ans. (1)Underfitting is a scenario in data science where a data model is unable to capture the relationship between the input and output variables accurately, generating a high error rate on both the training set and unseen data. It occurs when a model is too simple, which can be a result of a model needing more training time, more input features, or less regularization. Like overfitting, when a model is underfitted, it cannot establish the dominant trend within the data, resulting in training errors and poor performance of the model. If a model cannot generalize well to new data, then it cannot be leveraged for classification or prediction tasks. Generalization of a model to new data is ultimately what allows us to use machine learning algorithms every day to make predictions and classify data.\n",
    "\n",
    "High bias and low variance are good indicators of underfitting. Since this behavior can be seen while using the training dataset, underfitted models are usually easier to identify than overfitted ones.\n",
    "\n",
    "\n",
    "Reasons for Underfitting:\n",
    "\n",
    "a.High bias and low variance \n",
    "\n",
    "\n",
    "b.The size of the training dataset used is not enough.\n",
    "\n",
    "\n",
    "c.The model is too simple.\n",
    "\n",
    "\n",
    "d.Training data is not cleaned and also contains noise in it.\n",
    "\n",
    "\n",
    "(2). Overfitting: A statistical model is said to be overfitted when the model does not make accurate predictions on testing data. When a model gets trained with so much data, it starts learning from the noise and inaccurate data entries in our data set. And when testing with test data results in High variance. Then the model does not categorize the data correctly, because of too many details and noise. The causes of overfitting are the non-parametric and non-linear methods because these types of machine learning algorithms have more freedom in building the model based on the dataset and therefore they can really build unrealistic models. A solution to avoid overfitting is using a linear algorithm if we have linear data or using the parameters like the maximal depth if we are using decision trees. \n",
    "\n",
    "In a nutshell, Overfitting is a problem where the evaluation of machine learning algorithms on training data is different from unseen data.\n",
    "\n",
    "Reasons for Overfitting are as follows:\n",
    "\n",
    "\n",
    "a. High variance and low bias \n",
    "\n",
    "\n",
    "b.The model is too complex\n",
    "\n",
    "\n",
    "c.The size of the training data \n",
    "\n",
    "\n",
    "\n",
    "![title](https://media.geeksforgeeks.org/wp-content/uploads/20210323204619/imgonlinecomuaresizeLOjqonkALC.jpg)\n",
    "\n",
    "\n",
    "![title](https://media.geeksforgeeks.org/wp-content/cdn-uploads/20190523171258/overfitting_2.png)\n",
    "\n",
    "\n",
    "\n",
    "3.Bias Variance Tradeoff\n",
    "\n",
    "If the algorithm is too simple (hypothesis with linear eq.) then it may be on high bias and low variance condition and thus is error-prone. If algorithms fit too complex ( hypothesis with high degree eq.) then it may be on high variance and low bias. In the latter condition, the new entries will not perform well. Well, there is something between both of these conditions, known as Trade-off or Bias Variance Trade-off.\n",
    "\n",
    "This tradeoff in complexity is why there is a tradeoff between bias and variance. An algorithm can’t be more complex and less complex at the same time. For the graph, the perfect tradeoff will be like.\n",
    "\n",
    "\n",
    "![title](https://media.geeksforgeeks.org/wp-content/uploads/20200107023155/tradeoff.jpg)\n",
    "\n",
    "\n",
    "The best fit will be given by hypothesis on the tradeoff point.\n",
    "\n",
    "The error to complexity graph to show trade-off is given as –\n",
    "\n",
    "\n",
    "![title](https://media.geeksforgeeks.org/wp-content/uploads/20200107023418/1_oO0KYF7Z84nePqfsJ9E0WQ.png)\n",
    "\n",
    "\n",
    "This is referred to as the best point chosen for the training of the algorithm which gives low error in training as well as testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0bb204",
   "metadata": {},
   "source": [
    "### 5. Is it possible to boost the efficiency of a learning model? If so, please clarify how ?\n",
    "Ans: Building a machine learning model is not enough to get the right predictions, as you have to check the accuracy and need to validate the same to ensure get the precise results. And validating the model will improve the performance of the ML model. Some ways of boosting the efficiency of a learning model are mentioned below:\n",
    "\n",
    "1.Add more Data Samples\n",
    "\n",
    "\n",
    "2.Look at the problem differently: Looking at the problem from a new perspective can add valuable information to your model and help you uncover hidden relationships between the story variables. \n",
    "\n",
    "\n",
    "3.Asking different questions may lead to better results and, eventually, better accuracy.\n",
    "\n",
    "\n",
    "4.Adding Context to Data: More context can always lead to a better understanding of the problem and, eventually, better performance of the model. Imagine we are selling a car, a BMW. That alone doesn’t give us much information about the car. But, if we add the color, model and distance traveled, then you’ll start to have a better picture of the car and its possible value.\n",
    "\n",
    "\n",
    "5.Finetuning our hyperparameter: to get the answer, we will need to do some trial and error until you reach your answer.\n",
    "\n",
    "\n",
    "6.Train our model using cross-validation\n",
    "\n",
    "\n",
    "7.Expoerimenting with different Algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bb79eb",
   "metadata": {},
   "source": [
    "### 6. How would you rate an unsupervised learning model's success? What are the most common success indicators for an unsupervised learning model ?\n",
    "Ans: In case of supervised learning, it is mostly done by measuring the performance metrics such as accuracy, precision, recall, AUC, etc. on the training set and the holdout sets whereas for Unsupervised Learning it is different. Since there is no pre-evidence or records for patterns, we cannot directly compute the accuracy by comparing actual and predicted outputs but there exist many evaluation metrics to measure the performance of unsupervised learning algorithms after the training process.\n",
    "\n",
    "\n",
    "Some of them are-\n",
    "\n",
    "\n",
    "Clustering - Jaccard similarity index, Rand Index, Purity, Silhouette measure, Sum of squared errors, etc.\n",
    "\n",
    "\n",
    "Association rule mining – Lift, Confidence\n",
    "\n",
    "\n",
    "Time series analysis – Root mean square error, mean absolute error, mean absolute percentage error, etc.\n",
    "\n",
    "\n",
    "Autoencoders - Reconstruction errors\n",
    "\n",
    "\n",
    "Natural Language processing (like sentiment analysis and text clustering) – Comparing the correlation between natural words after converting them to numerical vectors.\n",
    "\n",
    "\n",
    "Principal component analysis – Reconstruction error, Scree plot\n",
    "\n",
    "\n",
    "Generative adversarial networks – Discriminator functions\n",
    "\n",
    "\n",
    "Recurrent neural networks and LSTM (In numerical series) – Root mean square error, mean absolute error, mean absolute percentage error, etc.\n",
    "\n",
    "\n",
    "Recurrent neural networks and LSTM (In semantic series) - Word to vector correlation\n",
    "\n",
    "\n",
    "Anomaly detection (like DBSCAN, OPTICS) – Cohesion, Separation, Sum of squared errors, etc.\n",
    "\n",
    "\n",
    "Expectation/ Maximization problems – Log-likelihood\n",
    "\n",
    "\n",
    "Survival analysis (Cox model 1) – Simple hazard ration, R Squared\n",
    "\n",
    "\n",
    "Survival analysis (Cox model 2) – Two group hazard ratio and brier score, Log-rank test, Somers’ rank correlation, Time-dependent ROC – AUC, Power validation, etc.\n",
    "\n",
    "Few other examples of such measures are:\n",
    "\n",
    "1.Silhouette coefficient.\n",
    "\n",
    "\n",
    "2.Calisnki-Harabasz coefficient.\n",
    "\n",
    "\n",
    "3.Dunn index.\n",
    "\n",
    "\n",
    "4.Xie-Beni score.\n",
    "\n",
    "\n",
    "5.Hartigan index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d4a4c9",
   "metadata": {},
   "source": [
    "### 7. Is it possible to use a classification model for numerical data or a regression model for categorical data with a classification model? Explain your answer ?\n",
    "Ans: Categorical Data is the data that generally takes a limited number of possible values. Also, the data in the category need not be numerical, it can be textual in nature. All machine learning models are some kind of mathematical model that need numbers to work with. This is one of the primary reasons we need to pre-process the categorical data before we can feed it to machine learning models.\n",
    "\n",
    "If a categorical target variable needs to be encoded for a classification predictive modeling problem, then the LabelEncoder class can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34c3312",
   "metadata": {},
   "source": [
    "### 8. Describe the predictive modeling method for numerical values. What distinguishes it from categorical predictive modeling ?\n",
    "Ans: predictive modeling is a statistical technique using machine learning and data mining to predict and forecast likely future outcomes with the aid of historical and existing data. It works by analyzing current and historical data and projecting what it learns on a model generated to forecast likely outcomes.\n",
    "\n",
    "Classification is the process of identifying the category or class label of the new observation to which it belongs.Predication is the process of identifying the missing or unavailable numerical data for a new observation. That is the key difference between classification and prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba780667",
   "metadata": {},
   "source": [
    "### 9. Make quick notes on:\n",
    "#### The process of holding out\n",
    "#### Cross-validation by tenfold\n",
    "#### Adjusting the parameters\n",
    "\n",
    "Ans: The Quick notes on the following topics is below:\n",
    "\n",
    "(1).The process of holding out:\n",
    "\n",
    "\n",
    "The hold-out method for training machine learning model is the process of splitting the data in different splits and using one split for training the model and other splits for validating and testing the models. The hold-out method is used for both model evaluation and model selection.\n",
    "\n",
    "\n",
    "(2)Cross-validation by tenfold: 10-fold cross validation would perform the fitting procedure a total of ten times, with each fit being performed on a training set consisting of 90% of the total training set selected at random, with the remaining 10% used as a hold out set for validation.\n",
    "\n",
    "\n",
    "(3)Adjusting the parameters:\n",
    "A fancy name for training: the selection of parameter values, which are optimal in some desired sense (eg. minimize an objective function you choose over a dataset you choose). The parameters are the weights and biases of the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381e7025",
   "metadata": {},
   "source": [
    "### 10. Define the following terms:\n",
    "#### Purity vs. Silhouette width\n",
    "#### Boosting vs. Bagging\n",
    "#### The eager learner vs. the lazy learner\n",
    "\n",
    "Ans: The Following is the short notes on:\n",
    "\n",
    "(1).Purity vs Silhouette width:\n",
    "\n",
    "\n",
    "Purity is a measure of the extent to which clusters contain a single class. Its calculation can be thought of as follows: For each cluster, count the number of data points from the most common class in said cluster.\n",
    "\n",
    "The silhouette width is also an estimate of the average distance between clusters. Its value is comprised between 1 and -1 with a value of 1 indicating a very good cluster.\n",
    "\n",
    "\n",
    "(2)Boosting vs. Bagging:\n",
    "\n",
    "\n",
    "Bagging is a way to decrease the variance in the prediction by generating additional data for training from dataset using combinations with repetitions to produce multi-sets of the original data.\n",
    "\n",
    "Boosting is an iterative technique which adjusts the weight of an observation based on the last classification.\n",
    "\n",
    "\n",
    "(2)The eager learner vs. the lazy learner:\n",
    "\n",
    "\n",
    "A lazy learner delays abstracting from the data until it is asked to make a prediction.\n",
    "while an eager learner abstracts away from the data during training and uses this abstraction to make predictions rather than directly compare queries with instances in the dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
